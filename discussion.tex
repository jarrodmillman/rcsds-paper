\section{Discussion}\label{discussion}

\subsection*{The balance between hands on and theoretical components}
This course was specifically designed to be as "practical" and "hands on" as
possible. However, reproducible computational science is not void of
theoretical aspects, and is not limited to an ad hoc set of tools. It is likely
that some conceptual work may still need to be done to extract the principles
of reproducible computational practices and teach the concepts and the models
to be adopted. This is already the attempt of this course for instance with
git, insisting on the underlying principles model and rationales (i.e. "how
does it work and why does it work this way?") of git rather than trying to
teach a list of commands associated with specific tasks. Currently,
reproducible computational science may still more be seen a set of tools and
good practices than a formal conceptual model, but this may evolve in the
future. We recommend that the more fundamental concepts were extracted and
highlighted in the teaching materials as far as possible. 

\subsection*{Prerequisites: could this work for Psychology students?}
As this specific course was taught to students in statistics, one can wonder
how generalizable to other population it can be. For instance, how would this
work for Psychology students? Some of the authors followed up with a course on
"practical neuroimaging" (Psych 214) and experienced how the project based
course could be delivered to students in psychology involved in brain imaging
project. While the number of students was limited, the feedback indicated that
the students considered that they learned important and a significant amount of
material.

\subsection*{Other format or length for this course?}
* Would this course be better as a two weeks "software carpentry" workshop? See the Neurohack (2) weeks in Seattle ?
* How would this work in a quarter system?
* Could this be done in a Mooc ? 

\subsection*{Students evaluation}
Student evaluation is not only necessary for the validation of the course by
the university administration, but, in our mind, should be designed primarily
to provide feedback to students as the course progresses. In our case, we based
our evaluation on quizzes, projects, and participation. We review briefly their
characteristics.
\begin{itemize}

\item Quizzes have several advantages: they can be corrected automatically, are
quick to perform. They can be challenging to construct in some situations, and
are not always best fitted for evaluating the most important pedagogical
components. In our case, we emphasized the collaborative and reproducibility
aspects and quizzes can not evaluate the overall success in making a
reproducible project.

\item Exercises typically would be designed to assess competency on one (or
possibly several) key concepts. They usually not only great for the evaluation
but participate to the students' learning, as it has been often noted that
"active learning, or learning through doing" is more effective than passive
learning. Exercises may be hard to design and answers may be difficult to mark
but they are a great learning tool. 

\item Projects have their own challenges. First, evaluation is
individual, and while git should permit to assess each individual contribution,
evaluation of each student contribution to the project remains a fairly
difficult task. 

\item Participation and laboratory session
While assessing students participation and reactivity in laboratory sessions is
important and is often a good indicator of how well the material is mastered,
these evaluations are subjective and may disadvantage shy students who may
master very well the material and be great contributors to a project.  

\end{itemize}

\subsection*{Other lessons learned from students' feedback}

Based on student feedback about the lab portion of the course, the breakout
exercises were extremely valuable to the students whereas the quizzes seemed
to be of less value.
Several students indicated that they had spent an inordinate amount of time in
preparation for the quizzes, in some cases as the expense of hands-on
experience with the computing tools.
This is counter to the goals of the quizzes and laboratory section in general,
and should be reviewed for future iterations of the course.
Given the positive feedback about the breakout exercises, one potential 
approach would be to replace the quizzes entirely by including a quantitative
evaluation component to the breakout exercises.
Additional effort would have to be devoted to designing the exercises so that
they could be objectively evaluated, with special emphasis on ensuring that
each student can be individually evaluated based on their understanding of the
concepts that the exercise is designed to highlight.
The ultimate goal would be to design a mechanism to ensure that the students
are gaining practical experience with the computing tools they will need for 
the final projects, while maintaining the appropriate perspective such that
students are not spending time on low-level tasks like memorizing syntax.
