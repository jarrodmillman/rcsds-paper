\section{Introduction}

Between us, we have many decades experience of teaching neuroimaging analysis.
% Matthew 1997- = 20
% JB 1997ish- 20
Like most other teachers of imaging, we have taught traditional courses with a
mixture of lectures covering the broad general ideas of the analysis, usually
combined with some practical workshops using imaging software.

We also have a great deal of experience of giving practical support for
imaging analysis to graduate students and post docs.

Our experience has gradually brought us to realize that we have three major
problems in the form of traditional teaching.

The first is that our students often leave their education with a superficial
understanding of imaging methods.  They are familiar with the steps, and the
terms, but when we ask them to reason about their analysis, they struggle.

The second problem is that the idealized picture in the lectures bears a
slight resemblance to their everyday work, which involves: using a Unix
computer, often remotely; collating and manipulating data; writing and sharing
scripts in computing languages such as Matlab or the Unix shell-scripting
languages.  Analyses can and do become messy and complicated, leading to
confusion and error.  Most labs expect students to learn how to do this on the
job, and few labs use current computing tools and process to control this
complexity, and reduce this error.  As a corollary, it is usually
difficult for a researcher to share their analysis with another
researcher, even in their own lab, and it is hard for the PI to check the
analysis for errors or invalid assumptions.

The final problem is that we have made it hard for imagers to collaborate with
other technical fields such as engineering and statistics.  Imaging software
packages are highly specific to brain imaging, and present an interface to
common statistical procedures that our students do not recognize.  Many
students have little background in standard engineering tools such as
convolution, the Fourier transform or numerical optimization.  In our
teaching, we usually gloss over the details of these fields, which saves us
time, but leaves the students without the understanding or vocabulary to
explain their analysis problem to other scientists in a way that makes it easy
for them to engage.  The result of our teaching may be that imaging research
is more likely to live in a neuroscience ghetto that is effectively walled off
from insight by and collaboration with other scientists.


traditional approach vs. our approach to teaching fMRI analysis ...

bottom up (low-level) vs. top down (high-level)

interdisciplinary

would it work?

\section{Material and Methods}

During the fall semester of 2015, we co-taught \emph{Reproducible and Collaborative
Statistical Data Science},\footnote{\url{http://www.jarrodmillman.com/stat159-fall2015/}}
a new project-based course offered through the Department of Statistics at UC Berkeley.
The course was open to upper-level undergraduates (as STAT 159) as well as
first- and second-year graduate students (as STAT 259).
Students were required to have a basic undergraduate level familiarity with
probability, statistics, and statistical computing in R.
Many students were from statistics and/or computer science; however, we had
students from many disciplines including cognitive science, psychology, and
architecture.
During the 15-week long semester, students were provided three hours of class
per week in two 90-minute sessions, plus two hours of labwork.
Students were expected to work at least eight hours per week outside class.
Projects were submitted two weeks after the last class.

\subsection{Course description}

\begin{quote}
A project-based introduction to statistical data analysis. Through case
studies, computer laboratories, and a term project, students learn
practical techniques and tools for producing statistically sound and
appropriate, reproducible, and verifiable computational answers to
scientific questions. Course emphasizes version control, testing,
process automation, code review, and collaborative programming.
Software tools include Bash, Git, Python, and \LaTeX.

\hfill\emph{---from the course catalog description}
\end{quote}

As the course title and catalog description suggests, \emph{Reproducible and
Collaborative Statistical Data Science} is a project-based course that
introduces students to reproducible and collaborative statistical research,
applied to a real scientific question.
Students gain experience acquiring, cleaning, and curating data; formulating
scientific questions statistically; developing appropriate statistical methods
to analyze the data to answer the scientific questions; implementing those
methods in robust, testable, reusable, extensible software; applying the
methods; visualizing the results; interpreting the results; and communicating
the results to others. Importantly, they learn to do this in a way that is
computationally reproducible.

The course is now regularly offered and the substantive scientific question(s)
the class addresses varies by instructor and semester.

...

Reproducibility and collaboration are too abstract in the absence of a
significant concrete project.
If you have a tiny dataset and a small handful of tiny functions, you can
just throw them all in a directory and post them online.
Problems compound as data grows, analysis complexity increases,
and lines of code multiply.

The semester project involved investigating\footnote{What each team means by
\emph{investigate} will need to be defined by each team.
For example, for one team this might mean a very careful reanalysis of the data
using the original methods as closely as possible.  However, this shouldn't
mean merely running existing scripts used in the original analysis; rather, the
team would need to reimplement the analysis scripts.  Another team might decide
to conduct a different analysis than used in the original study.  For instance,
the published work might use a parametric approach and the team project might
attempt to use a nonparametric technique such as permutation testing.  A third
team might focus on a careful validation of the modeling assumptions made by
the original analysis.}
a published result using the analysis of neuroimaging data.
There was no requirement for students for students to have a background in
neuroscience.
The intention of focusing on neuroimaging data was  merely to provide a
concrete problem domain that exemplifies the types of programming and
statistical challenges present in many modern statistical applications.

The weekly lectures and labs prepared students---through a
series of guided exercises---with the basic skills and
background needed for the group project.
While we demonstrated basic methods and tools during lecture and lab,
students were expected to do additional research and reading in the course
of working on the group project.
For instance, they may have needed to use a specialized analysis
method or a Python package not covered in the lectures or labs.

The majority of the class focused on a final group project

\begin{quote}
\textbf{Learning objectives:} Investigate a published fMRI study;
collaborate on a software project; work with complex and large datasets;

As part of your final project grade, you will be required to work on your
project using GitHub's pull request and code review mechanism.  During lecture,
I will cover the exact workflow you will be expected to follow.  Please note
that as this course is explicitly about reproducibility and collaboration your
project grade will not be entirely based on your final report, but will also
reflect how well your group work is reproducible and how effectively you
collaborated using the techniques taught in the course (e.g., pull requests,
code review, testing, etc.)
\end{quote}

\begin{quote}
\begin{flushleft}
Form teams \dotfill Week 5 (Sept. 22)\\
Project proposal \dotfill Week 6 (Oct. 1)\\
Progress presentation \dotfill Week 12 (Nov. 12)\\
Draft report \dotfill Week 12 (Nov. 12)\\
Project presentation \dotfill Week 15 (Dec. 1 \& 3)\\
Final report \dotfill Week 17 (Dec. 14)\\
\end{flushleft}
\end{quote}

\subsection{Core topics}

Our objective for the course was for students to
(a) be proficient at the Unix commandline,
(b) be expert at version control with Git,
(c) be able to write documents in Markdown and \LaTeX,
(d) be familiar with scientific computing in Python,
(e) understand the computational and statistical issues involved with reproducibility, and
(f) be familiar with computational issues in modern statistical data
analysis through hands-on analysis of neuroimaging data.


Introduction and course overview. What is the difference between
reproducibility, replicability, verifiability, and auditability? Why is
reproducibility important to the scientific method?

Introduction to the scientific problem for the semester
and the data sources for the project.


\subsubsection{The software stack}


reproducible research \citep{millman2014developing}

Python for neuroimaging analysis \citep{millman2007analysis}

Scientific Python \citep{millman2011python}

As if you were working in a scientific research group or in industry, you will
be given a set of tools (a ``software stack'') and practices you are required to
master and use. As if you were working in a scientific research group or in
industry, you will be pointed to resources to help you learn the tools, and it
is your responsibility to ensure that you have mastered them, which will
require a substantial amount of time outside class. And, as if you were working
in a scientific research group or in industry, you will be required to
collaborate and to take responsibility for your role in the collaboration.

But the point is not merely to master the tools or to learn to collaborate
effectively.  Rather, the point is to do sound computational science, and to do
it in a way that others can verify the data and statistical techniques behind
your analysis, can verify that your code does what it’s supposed to do, can run
the code using the data and parameters you used, can verify that they get the
same results you do, and can build on what you have done to advance science
even further.

\paragraph*{The UNIX environment}
Introduction to the command line
interface, the filesystem hierarchy, and working with text files. Introduce
version control with Git focusing on conceptual model and basic objects.

Using the bash shell;
Introduction to Git;
Introduction to Python;

\paragraph*{Scientific computing with Python}

Introduction to the scientific Python software stack.

Python data structures and control flow.  Basic NumPy, SciPy, and matplotlib.

Introduction to functional programming in Python including iterators, generators,
list comprehension, zip, map, enumerate, etc.  Unit testing in Python.  More advanced
Git.

Introduction to project organization and process automation including: Python
packages and setuptools; makefiles; markdown, reStructuredText, and LaTeX; and
automated testing and continuous integration. Collaborative workflows with Git.



\subsubsection{Neuroimaging data analysis}

convolution (hemodynamic modeling, smoothing);

interpolation (slice time correction, image resampling);

optimization (registration, advanced statistics);

basic linear algebra (statistics).

\subsubsection{Reading list}

Annotated reading list?

\begin{itemize}
\item \textbf{Reading 1}: \href{https://osf.io/zqbu2}{L Preeyanon, AB Pyrkosz, and CT Brown.
             ``Reproducible bioinformatics research for biologists.''
Implementing Reproducible Research (2014)}
\item \textbf{Reading 2}: \href{http://arxiv.org/pdf/0906.3662v1}{MA Lindquist. ``The statistical analysis of fMRI data.''}
              %Statistical Science 23.4 (2008)
(2008)
\item \textbf{Reading 3}: \href{http://www.computer.org/cms/Computer.org/ComputingNow/issues/2015/04/T-mcs2011020013.pdf}{F P\'{e}rez, BE Granger, and JD Hunter.
              ``Python: an ecosystem for scientific computing.''}
              %Computing in Science \& Engineering 13.2 (2011)
(2011)
\item \textbf{Reading 4}: \href{http://statweb.stanford.edu/~wavelab/Wavelab_850/wavelab.pdf}{JB Buckheit and DL Donoho.
``Wavelab and reproducible research.'' (1995)}
\item \textbf{Reading 5}: \href{http://www.jarrodmillman.com/publications/millman2014developing.pdf}{KJ Millman and F P\'{e}rez.
              ``Developing open source scientific practice.''}
              %Implementing Reproducible Research (2014)
(2014)
\item \textbf{Reading 6}: \href{http://matthew.dynevor.org/_downloads/does_glm_love.pdf}{JB Poline and M Brett. ``The general linear model and fMRI: does love last forever?'' (2012)}
\item \textbf{Reading 7}: \href{http://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124}{JPA Ioannidis. ``Why Most Published Research Findings Are False'' (2005)}
\end{itemize}

\subsubsection{Labs, homeworks, and quizzes}


...


\section{Results}

12 teams of 3 to 5 students

See Table~\ref{rubric} for the final project grading rubric.

\url{https://raw.githubusercontent.com/jarrodmillman/rcsds/master/notes/rubric.rst}

\url{http://www.jarrodmillman.com/rcsds/notes/rubric.pdf}

Grading included checking that I could reproduce everyone's work, reviewing pull
requests and code contributions, checking that all code included
(passing) tests, reviewing code to see if it was well written, and
reading the final reports among other things). 

discuss general quality

discuss a couple of example projects
\citep{tom2007neural}

\section{Discussion}

How would this work for Psychology students?  Psych 214 follow-up

How would this work in a quarter system?

lessons learned ...


\section*{Conflict of Interest Statement}

The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.

\section*{Author Contributions}

KJM was the lead instructor and was responsible for the syllabus and project timeline;
KJM and MB were responsible for lectures and created homework assignments;
KJM and RB were responsible for labs, readings, quizzes, and grading;
all authors held weekly office hours to assist students with their projects.
KJM and MB wrote the first draft of the manuscript;
all authors wrote sections of the manuscript, contributed to manuscript revision, 
as well as read and approved the submitted version.
